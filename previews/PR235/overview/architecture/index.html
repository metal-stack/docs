<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Architecture · metal-stack</title><meta name="title" content="Architecture · metal-stack"/><meta property="og:title" content="Architecture · metal-stack"/><meta property="twitter:title" content="Architecture · metal-stack"/><meta name="description" content="Documentation for metal-stack."/><meta property="og:description" content="Documentation for metal-stack."/><meta property="twitter:description" content="Documentation for metal-stack."/><meta property="og:url" content="https://docs.metal-stack.io/overview/architecture/"/><meta property="twitter:url" content="https://docs.metal-stack.io/overview/architecture/"/><link rel="canonical" href="https://docs.metal-stack.io/overview/architecture/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../assets/youtube.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="metal-stack logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">metal-stack</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Introduction</a></li><li><span class="tocitem">Overview</span><ul><li class="is-active"><a class="tocitem" href>Architecture</a><ul class="internal"><li><a class="tocitem" href="#Target-Deployment-Platforms"><span>Target Deployment Platforms</span></a></li><li><a class="tocitem" href="#Metal-Control-Plane"><span>Metal Control Plane</span></a></li><li><a class="tocitem" href="#Partitions"><span>Partitions</span></a></li><li><a class="tocitem" href="#Complete-View"><span>Complete View</span></a></li><li><a class="tocitem" href="#Machine-Provisioning-Sequence"><span>Machine Provisioning Sequence</span></a></li><li><a class="tocitem" href="#Offline-Resilience"><span>Offline Resilience</span></a></li></ul></li><li><a class="tocitem" href="../networking/">Networking</a></li><li><a class="tocitem" href="../hardware/">Hardware Support</a></li><li><a class="tocitem" href="../os/">Operating Systems</a></li><li><a class="tocitem" href="../kubernetes/">Kubernetes Integration</a></li><li><a class="tocitem" href="../isolated-kubernetes/">Isolated Kubernetes</a></li><li><a class="tocitem" href="../gpu-support/">GPU Support</a></li><li><a class="tocitem" href="../storage/">Storage</a></li><li><a class="tocitem" href="../comparison/">Comparison</a></li></ul></li><li><a class="tocitem" href="../../quickstart/">Quickstart</a></li><li><span class="tocitem">Installation &amp; Administration</span><ul><li><a class="tocitem" href="../../installation/deployment/">Installation</a></li><li><a class="tocitem" href="../../installation/autonomous-control-plane/">Autonomous Control Plane</a></li><li><a class="tocitem" href="../../installation/updates/">Releases and Updates</a></li><li><a class="tocitem" href="../../installation/monitoring/">Monitoring</a></li><li><a class="tocitem" href="../../installation/troubleshoot/">Troubleshoot</a></li></ul></li><li><span class="tocitem">User Guides</span><ul><li><a class="tocitem" href="../../external/mini-lab/README/">mini-lab</a></li><li><a class="tocitem" href="../../external/metalctl/README/">metalctl</a></li><li><a class="tocitem" href="../../external/csi-driver-lvm/README/">csi-driver-lvm</a></li><li><a class="tocitem" href="../../external/firewall-controller/README/">firewall-controller</a></li></ul></li><li><a class="tocitem" href="../../apidocs/apidocs/">API Documentation</a></li><li><span class="tocitem">Development</span><ul><li><a class="tocitem" href="../../development/client_libraries/">Client Libraries</a></li><li><a class="tocitem" href="../../development/roadmap/">Roadmap</a></li><li><a class="tocitem" href="../../development/proposals/">Enhancement Proposals</a></li><li><a class="tocitem" href="../../development/contributing/">Contributing</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Overview</a></li><li class="is-active"><a href>Architecture</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Architecture</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/metal-stack/docs.git" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="github.com/metal-stack/docs.git" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Architecture"><a class="docs-heading-anchor" href="#Architecture">Architecture</a><a id="Architecture-1"></a><a class="docs-heading-anchor-permalink" href="#Architecture" title="Permalink"></a></h1><p>The metal-stack is a compound of microservices predominantly written in <a href="https://go.dev/">Golang</a>.</p><p>This page gives you an overview over which microservices exist, how they communicate with each other and where they are deployed.</p><ul><li><a href="#Architecture">Architecture</a></li><li class="no-marker"><ul><li><a href="#Target-Deployment-Platforms">Target Deployment Platforms</a></li><li><a href="#Metal-Control-Plane">Metal Control Plane</a></li><li><a href="#Partitions">Partitions</a></li><li><a href="#Complete-View">Complete View</a></li><li><a href="#Machine-Provisioning-Sequence">Machine Provisioning Sequence</a></li><li><a href="#Offline-Resilience">Offline Resilience</a></li></ul></li></ul><h2 id="Target-Deployment-Platforms"><a class="docs-heading-anchor" href="#Target-Deployment-Platforms">Target Deployment Platforms</a><a id="Target-Deployment-Platforms-1"></a><a class="docs-heading-anchor-permalink" href="#Target-Deployment-Platforms" title="Permalink"></a></h2><p>For our environments, we chose to deploy the metal-stack into a Kubernetes cluster. This means that also our entire installation was developed for metal-stack being run on Kubernetes. Running applications on Kubernetes gives you a lot of benefits regarding ease-of-deployment, scalability, reliability and so on.</p><p>However, very early we decided that we do not want to depend on technical Kubernetes functionality with our software (i.e. we did not implement the stack &quot;kube-native&quot; by using controllers and Kubernetes CRDs and things like that). With the following paragraph we want to point out the reasoning behind this &quot;philosophical&quot; decision that may sound conservative at first glance. But not relying on Kubernetes technology:</p><ul><li>Makes deployments of the stack without Kubernetes theoretically possible.<ul><li>We believe that cloud providers should be able to act beneath Kubernetes</li><li>This way it is possible to use metal-stack for providing your own Kubernetes offering without relying on Kubernetes yourself (breaks the chicken-egg problem)</li></ul></li><li>Follows an important claim in microservice development: &quot;Be agnostic to your choice of technology&quot;<ul><li>For applications that are purely made for being run on Kubernetes, it does not matter to rely on this technology (we even do the same a lot with our applications that integrate the metal-stack with Gardener) but as soon as you start using things like the underlying reconciliation abilities (which admittedly are fanstatic) you are locking your code into a certain technology</li><li>We don&#39;t know what comes after Kubernetes but we believe that a cloud offering should have the potential to survive a choice of technology</li><li>By this decision we ensured that we can migrate the stack to another future technology and survive the change</li></ul></li></ul><p>One more word towards determining the location for your metal control plane: It is not strictly required to run the control plane inside the same data center as your servers. It even makes sense not to do so because this way you can place your control plane and your servers into a different failure domains, which makes your installation more robust to data center meltdown. Externally hosting the control plane brings you up and running quickly plus having the advantage of higher security through geo-distribution.</p><h2 id="Metal-Control-Plane"><a class="docs-heading-anchor" href="#Metal-Control-Plane">Metal Control Plane</a><a id="Metal-Control-Plane-1"></a><a class="docs-heading-anchor-permalink" href="#Metal-Control-Plane" title="Permalink"></a></h2><p>The foundation of the metal-stack is what we call the <em>metal control plane</em>.</p><p>The control plane contains a couple of essential microservices for the metal-stack including:</p><ul><li><strong><a href="https://github.com/metal-stack/metal-api">metal-api</a></strong> The API to manage control plane resources like machines, switches, operating system images, machine sizes, networks, IP addresses and more. The exposed API is an old-fashioned REST API with different authentication methods. The metal-api stores the state of these entities in a <a href="https://rethinkdb.com/">RethinkDB</a> database. The metal-api also has its own IP address management (<a href="https://github.com/metal-stack/go-ipam">go-ipam</a>), which writes IP address and network allocations into a PostgreSQL backend.</li><li><strong><a href="https://github.com/metal-stack/masterdata-api">masterdata-api</a></strong> Manages tenant and project entities, which can be described as entities used for company-specific resource separation and grouping. Having these &quot;higher level entities&quot; managed by a separate microservice was a design choice that allows to re-use the information by other microservices without having them to know the metal-api at all. The masterdata gets persisted in a dedicated PostgreSQL database.</li><li><strong><a href="https://github.com/metal-stack/metal-console">metal-console</a></strong> Provides access for users to a machine&#39;s serial console via SSH. It can be seen as an optional component.</li><li><strong><a href="https://nsq.io/">nsq</a></strong> A message queuing system (not developed by the metal-stack) used for decoupling microservices and distributing tasks.</li></ul><p>The following figure shows the relationships between these microservices:</p><p><img src="../metal-stack-control-plane.svg" alt="Metal Control Plane"/></p><blockquote><p>Figure 1: The metal control plane deployed in a Kubernetes environment with an ingress-controller exposing additional services via <a href="https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services/">service exposal</a>.</p></blockquote><p>Some notes on this picture:</p><ul><li>Users can access the metal-api with the CLI client called <a href="https://github.com/metal-stack/metalctl">metalctl</a>.</li><li>You can programmatically access the metal-api with <a href="../../development/client_libraries/">client libraries</a> (e.g. <a href="https://github.com/metal-stack/metal-go">metal-go</a>).</li><li>Our databases are wrapped in a specially built <a href="https://github.com/metal-stack/backup-restore-sidecar">backup-restore-sidecar</a>, which is consistently backing up the databases in external blob storage.</li><li>The metal-api can be scaled out using replicas when being deployed in Kubernetes.</li></ul><h2 id="Partitions"><a class="docs-heading-anchor" href="#Partitions">Partitions</a><a id="Partitions-1"></a><a class="docs-heading-anchor-permalink" href="#Partitions" title="Permalink"></a></h2><p>A <em>partition</em> is our term for describing hardware in the data center controlled by the metal-stack with all the hardware participating in the same network topology. Being in the same network topology causes the hardware inside a partition to build a failure domain. Even though the network topology for running the metal-stack is required to be redundant by design, you should consider setting up multiple partitions. With multiple partitions it is possible for users to maintain availability of their applications by spreading them across the partitions. Installing partitions in multiple data centers would be even better in regards of fail-safe application performance, which would even tolerate the meltdown of a data center.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>In our setups, we encode the name of a region and a zone name into our partition names. However, we do not have dedicated entities for regions and zones in our APIs.</p><p>A <strong>region</strong> is a geographic area in which data centers are located.</p><p><strong>Zones</strong> are geographic locations in a region usually in different fire compartments. Regions can consist of several zones.</p><p>A zone can consist of several <strong>partitions</strong>. Usually, a partition spans a rack or a group of racks.</p></div></div><p>We strongly advise to group your hardware into racks that are specifically assembled for running metal-stack. When using modular rack design, the amount of compute resources of a partition can easily be extended by adding more racks to your partition.</p><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>The hardware that we currently support to be placed inside a partition is described in the <a href="../hardware/">hardware</a> document.</p></div></div><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>How large you can grow your partitions and how the network topology inside a partition looks like is described in the <a href="../networking/">networking</a> document.</p></div></div><p>The metal-stack has microservices running on the leaf switches in a partition. For this reason, your leaf switches are required to run a Linux distribution that you have full access to. Additionally, there are a servers not added to the pool of user-allocatable machines, which are instead required for running metal-stack and we call them <em>management servers</em>. We also call the entirety of switches inside a partition the <em>switch plane</em>.</p><p>The microservices running inside a partition are:</p><ul><li><strong><a href="https://github.com/metal-stack/metal-hammer">metal-hammer</a></strong> (runs on a server when not allocated by user, often referred to as <em>discovery image</em>) An initrd, which is booted up in PXE mode, preparing and registering a machine. When a user allocates a machine, the metal-hammer will install the target operating system on this machine and kexec into the new operating system kernel.</li><li><strong><a href="https://github.com/metal-stack/metal-core">metal-core</a></strong> (runs on leaf switches) Dynamically configures the leaf switch from information provided by the metal-api. It also proxies requests from the metal-hammer to the metal-api including publishment of machine lifecycle events and machine registration requests.</li><li><strong><a href="https://github.com/danderson/netboot/tree/master/pixiecore">pixiecore</a></strong> (preferably runs on management servers, forked by metal-stack) Provides the capability of PXE booting servers in the PXE boot network.</li><li><strong><a href="https://github.com/metal-stack/metal-bmc">metal-bmc</a></strong> (runs on management servers) Reports the ip addresses that are leased to ipmi devices together with their machine uuids to the metal-api. This provides machine discovery in the partition machines and keeps all IPMI interface access data up-to-date. Also forwards metal-console requests to the actual machine, allowing user access to the machine&#39;s serial console. Furthermore it processes firmware updates and power on/off, led on/off, boot order changes.</li></ul><p><img src="../metal-stack-partition.svg" alt="Partition"/></p><blockquote><p>Figure 2: Simplified illustration of services running inside a partition.</p></blockquote><p>Some notes on this picture:</p><ul><li>This figure is slightly simplified. The switch plane consists of spine switches, exit routers, management firewalls and a bastion router with more software components deployed on these entities. Please refer to the <a href="../networking/">networking</a> document to see the full overview over the switch plane.</li><li>The image-cache is an optional component consisting of multiple services to allow caching images from the public image store inside a partition. This brings increased download performance on machine allocation and increases independence of a partition on the internet connection.</li></ul><h2 id="Complete-View"><a class="docs-heading-anchor" href="#Complete-View">Complete View</a><a id="Complete-View-1"></a><a class="docs-heading-anchor-permalink" href="#Complete-View" title="Permalink"></a></h2><p>The following figure shows several partitions connected to a single metal control plane. Of course, it is also possible to have multiple metal control planes, which can be useful for staging.</p><p><img src="../metal-stack-architecture.drawio.svg" alt="metal-stack"/></p><blockquote><p>Figure 3: Reduced view on the communication between the metal control plane and multiple partitions.</p></blockquote><p>Some notes on this picture:</p><ul><li>By design, a partition only has very few ports open for incoming-connections from the internet. This contributes to a smaller attack surface and higher security of your infrastructure.</li><li>With the help of NSQ, it is not required to have connections from the metal control plane to the metal-core. The metal-core instances register at the message bus and can then consume partition-specific topics, e.g. when a machine deletion gets issued by a user.</li></ul><h2 id="Machine-Provisioning-Sequence"><a class="docs-heading-anchor" href="#Machine-Provisioning-Sequence">Machine Provisioning Sequence</a><a id="Machine-Provisioning-Sequence-1"></a><a class="docs-heading-anchor-permalink" href="#Machine-Provisioning-Sequence" title="Permalink"></a></h2><p>The following sequence diagram illustrates some of the main principles of the machine provisioning lifecycle.</p><p><img src="../provisioning_sequence.drawio.svg" alt="provisioning sequence"/></p><blockquote><p>Figure 4: Sequence diagram of the machine provisioning sequence.</p></blockquote><p>Here is a video showing a screen capture of a machine&#39;s serial console while running the metal-hammer in &quot;wait mode&quot;. Then, a user allocates the machine and the metal-hammer installs the target operating system and the machine boots into the new operating system kernel via the kexec system call.</p><div class="video-container">
<iframe src="https://www.youtube-nocookie.com/embed/3oEhInk6BaU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div><h2 id="Offline-Resilience"><a class="docs-heading-anchor" href="#Offline-Resilience">Offline Resilience</a><a id="Offline-Resilience-1"></a><a class="docs-heading-anchor-permalink" href="#Offline-Resilience" title="Permalink"></a></h2><p>It is possible to use metal-stack without any external network dependencies by integrating your own DNS and NTP configuration into the stack. This feature is great for workloads requiring strong independence and reliability. Even in case of an internet connection failure, your infrastructure remains operational. Existing machines do not encounter any downtime as well as new machines can be provisioned. All you need to have in place is a DNS and NTP server configured and accessible for metal-stack.</p><p>NTP servers need to be configured on the pixiecore and the metal-hammer microservices. This can be achieved by providing a list of NTP servers with the following Ansible variable through metal-roles:</p><pre><code class="language-yaml hljs">pixiecore_metal_hammer_ntp_servers: []</code></pre><p>In the background, the pixiecore is taking the NTP servers and passing it via the <code>MetalConfig</code> to the metal-hammer. When booting bare-metal servers, the metal-hammer needs to configure NTP servers. It recognises the ones from the <code>MetalConfig</code> and configures itself accordingly. If no NTP servers are passed along, the following standard servers are used:</p><ul><li>0.de.pool.ntp.org</li><li>1.de.pool.ntp.org</li><li>2.de.pool.ntp.org</li></ul><p>Moreover, machine and firewall images need to be configured with your custom DNS and NTP servers. The customisation can be made via the fields <code>ntp_servers</code> an <code>dns_servers</code> and specifying a list of servers in the creation request for the machine or firewall.</p><p>Within a partition default values for DNS and NTP servers can be configured. They are applied to all machines and firewalls within this partition, but can be replaced by specifying different ones inside the machine allocation request.</p><p>Thus, for creating a partition as well as a machine or a firewall, the flags <code>dnsservers</code> and <code>ntpservers</code> can be provided within the <code>metalctl</code> command.</p><p>In order to be fully offline resilient, make sure to check out <code>metal-image-cache-sync</code>. This component provides copies of <code>metal-images</code>, <code>metal-kernel</code> and <code>metal-hammer</code>.</p><p>This feature is related to <a href="https://docs.metal-stack.io/dev/development/proposals/MEP14/README/">MEP14</a>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Introduction</a><a class="docs-footer-nextpage" href="../networking/">Networking »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Monday 13 January 2025 08:40">Monday 13 January 2025</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
