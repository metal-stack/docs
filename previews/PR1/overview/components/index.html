<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Components · metal-stack</title><link rel="canonical" href="https://metal-stack.github.io/docs/master/overview/components/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="metal-stack logo"/></a><div class="docs-package-name"><span class="docs-autofit">metal-stack</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Introduction</a></li><li><span class="tocitem">Overview</span><ul><li class="is-active"><a class="tocitem" href>Components</a><ul class="internal"><li><a class="tocitem" href="#Metal-Control-Plane-1"><span>Metal Control Plane</span></a></li><li><a class="tocitem" href="#Partitions-1"><span>Partitions</span></a></li><li><a class="tocitem" href="#Entire-Picture-1"><span>Entire Picture</span></a></li><li><a class="tocitem" href="#Machine-Provisioning-Sequence-1"><span>Machine Provisioning Sequence</span></a></li></ul></li><li><a class="tocitem" href="../networking/">Networking</a></li><li><a class="tocitem" href="../os/">Operating Systems</a></li><li><a class="tocitem" href="../hardware/">Hardware Support</a></li><li><a class="tocitem" href="../kubernetes/">Kubernetes Integration</a></li></ul></li><li><a class="tocitem" href="../../quickstart/">Quickstart</a></li><li><span class="tocitem">Guides</span><ul><li><a class="tocitem" href="../../external/mini-lab/README/">mini-lab</a></li><li><a class="tocitem" href="../../external/metalctl/README/">metalctl</a></li></ul></li><li><span class="tocitem">Installation &amp; Maintenance</span><ul><li><a class="tocitem" href="../../installation/preparations/">Preparations</a></li><li><a class="tocitem" href="../../installation/deployment/">Installation</a></li><li><a class="tocitem" href="../../installation/monitoring/">Monitoring</a></li><li><a class="tocitem" href="../../installation/troubleshoot/">Troubleshoot</a></li></ul></li><li><a class="tocitem" href="../../api_docs/">API Documentation</a></li><li><a class="tocitem" href="../../proposals/">Enhancement Proposals</a></li><li><a class="tocitem" href="../../contributing/">Contributing</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Overview</a></li><li class="is-active"><a href>Components</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Components</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/metal-stack/docs/blob/master/docs/src/overview/components.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Components-1"><a class="docs-heading-anchor" href="#Components-1">Components</a><a class="docs-heading-anchor-permalink" href="#Components-1" title="Permalink"></a></h1><p>The metal-stack is a compound of microservices written in <a href="https://golang.org/">Golang</a>.</p><p>This page gives you an overview over which microservices exist, how they communicate with each other and where they are deployed.</p><ul><li><a href="#Components-1">Components</a></li><ul><li><a href="#Metal-Control-Plane-1">Metal Control Plane</a></li><li><a href="#Partitions-1">Partitions</a></li><li><a href="#Entire-Picture-1">Entire Picture</a></li><li><a href="#Machine-Provisioning-Sequence-1">Machine Provisioning Sequence</a></li></ul></ul><h2 id="Metal-Control-Plane-1"><a class="docs-heading-anchor" href="#Metal-Control-Plane-1">Metal Control Plane</a><a class="docs-heading-anchor-permalink" href="#Metal-Control-Plane-1" title="Permalink"></a></h2><p>The foundation of the metal-stack is what we call the <em>metal control plane</em>. The metal control plane is typically deployed in a Kubernetes cluster and is not strictly required to run inside your data center. It even makes sense not to place the metal control plane in the same failure domain with your servers that you are going to manage with the metal-stack. The control plane does not depend on Kubernetes functionality, such that deployments to other target platforms are theoretically possible.</p><p>The control plane contains of a couple of essential microservices for the metal-stack including:</p><ul><li><strong><a href="https://github.com/metal-stack/metal-api">metal-api</a></strong> The API to manage and control resources like machines, switches, operating system images, machine sizes, networks, IP addresses and more. The metal-api stores the state of these entities in a <a href="https://rethinkdb.com/">RethinkDB</a> database. The metal-api also has it&#39;s own IP address management (<a href="https://github.com/metal-stack/go-ipam">go-ipam</a>), which writes IP address and network allocations into a PostgreSQL backend.</li><li><strong><a href="https://github.com/metal-stack/masterdata-api">masterdata-api</a></strong> Manages tenant and project entities, which can be described as entities used for company-specific resource separation and grouping. Having these &quot;higher level entities&quot; managed by a separate microservice was a design choice that allows to re-use the information by other microservices without having them to know the metal-api at all. The masterdata gets persisted in a dedicated PostgreSQL database.</li><li><strong><a href="https://github.com/metal-stack/metal-console">metal-console</a></strong> Provides access for users to a machine&#39;s serial console via SSH. It can be seen as an optional component.</li><li><strong><a href="https://nsq.io/">nsq</a></strong> A message queuing system (not developed by the metal-stack) used for decoupling microservices and distributing tasks.</li></ul><p>The following figure shows the relationships between these microservices:</p><p><img src="../control-plane.svg" alt="Metal Control Plane"/></p><blockquote><p>Figure 1: The metal control plane deployed in a Kubernetes environment with an ingress-controller exposing additional services via <a href="https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services/">service exposal</a>.</p></blockquote><p>Some notes on this picture:</p><ul><li>Users can access the metal-api with the CLI client called <a href="https://github.com/metal-stack/metalctl">metalctl</a>.</li><li>Our databases are wrapped in a specially built <a href="https://github.com/metal-stack/backup-restore-sidecar">backup-restore-sidecar</a>, which is consistently backing up the databases in external blob storage.</li><li>The metal-api can be scaled out in Kubernetes using replicas.</li></ul><h2 id="Partitions-1"><a class="docs-heading-anchor" href="#Partitions-1">Partitions</a><a class="docs-heading-anchor-permalink" href="#Partitions-1" title="Permalink"></a></h2><p>A <em>partition</em> is our term for describing hardware in the data center controlled by the metal-stack with all the hardware participating in the same network topology. Typically, a partition spans a rack or a group of racks. Being in the same network topology causes the hardware inside a partition to build a failure domain. Even though the network topology for running the metal-stack is required to be redundant by design, you should consider setting up multiple partitions. With multiple partitions it is possible for users to maintain availability of their applications by spreading them across the partitions. Installing partitions in multiple data centers would be even better in regards of fail-safe application performance, which would even tolerate the meltdown of a data center.</p><p>We strongly advise to group your hardware into racks that are specifically assembled for running metal-stack. When using modular rack design, extending the amount of compute resources of a partition can easily be done by adding more racks to your partition.</p><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>The hardware that we currently support to be placed inside a partition is described in the <a href="../hardware/">hardware</a> document.</p></div></div><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>How large you can grow your partitions and how the network topology inside a partition looks like is described in the <a href="../networking/">networks</a> section.</p></div></div><p>The metal-stack has microservices running on the leaf switches in a partition. For this reason, your leaf switches are required to run a Linux distribution that you have full access to. Additionally, there are a servers not added to the pool of user-allocatable machines, which are instead required for running metal-stack and we call them <em>management servers</em>.</p><p>The microservices running inside a partition are:</p><ul><li><strong><a href="https://github.com/metal-stack/metal-core">metal-core</a></strong> (runs on leaf switches) Dynamically configures the leaf switch from information provided by the metal-api.</li><li><strong><a href="https://github.com/danderson/netboot/tree/master/pixiecore">pixiecore</a></strong> (runs on leaf switches, not developed by metal-stack) Provides the capability of PXE booting servers in the PXE boot network.</li><li><strong><a href="https://github.com/metal-stack/metal-hammer">metal-hammer</a></strong> (runs on a server when not allocated by user) An initrd, which is booted up in PXE mode, preparing and registering a machine. When a user allocates a machine, the metal-hammer will install the target operating system on this machine and kexec into the new operating system kernel.</li><li><strong><a href="https://github.com/metal-stack/metal-console">bmc-proxy</a></strong> (runs on management servers) Belongs to the metal-console, allowing user access to the machine&#39;s serial console. It can be seen as an optional component.</li><li><strong><a href="https://github.com/metal-stack/ipmi-catcher">ipmi-catcher</a></strong> (runs on management servers) Reports the ip addresses that are leased to ipmi devices together with their machine uuids to the metal-api. This provides machine discovery in the partition machines and keeps all IPMI interface access data up-to-date.</li></ul><p><strong>TODO: add figure</strong></p><h2 id="Entire-Picture-1"><a class="docs-heading-anchor" href="#Entire-Picture-1">Entire Picture</a><a class="docs-heading-anchor-permalink" href="#Entire-Picture-1" title="Permalink"></a></h2><p><strong>TODO: add figure</strong></p><p>By design, a partition only has very few ports open for incoming-connections from the internet. This contributes to a smaller attack surface and higher security of your infrastructure.</p><h2 id="Machine-Provisioning-Sequence-1"><a class="docs-heading-anchor" href="#Machine-Provisioning-Sequence-1">Machine Provisioning Sequence</a><a class="docs-heading-anchor-permalink" href="#Machine-Provisioning-Sequence-1" title="Permalink"></a></h2></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Introduction</a><a class="docs-footer-nextpage" href="../networking/">Networking »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 2 June 2020 11:26">Tuesday 2 June 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
